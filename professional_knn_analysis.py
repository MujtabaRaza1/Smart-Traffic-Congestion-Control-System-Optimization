#!/usr/bin/env python3
"""
Professional k-NN Analysis for Smart Traffic Congestion Control System
=========================================================================

This script implements k-NN classifiers with varying numbers of neighbors to predict
traffic congestion levels using the synthetic traffic data generated by the system.
The visualization follows professional publication standards with proper styling.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Set the style for plots
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_context("paper", font_scale=1.2)

# Load the synthetic traffic data
print("Loading traffic data...")
traffic_data = pd.read_csv('data/synthetic_traffic_data.csv')

# Display basic information about the dataset
print(f"Dataset shape: {traffic_data.shape}")
print(f"Columns: {traffic_data.columns.tolist()}")

# Convert congestion to binary classes (high/low congestion) for classification
# Let's consider congestion > 0.7 as high congestion
traffic_data['congestion_class'] = (traffic_data['congestion'] > 0.7).astype(int)

# Select features for prediction with domain knowledge
features = [
    'hour', 'day_of_week', 'is_weekend', 'is_rush_hour', 
    'volume', 'speed', 'precipitation', 'incident'
]

# Create feature matrix X and target vector y
X = traffic_data[features]
y = traffic_data['congestion_class']

# Split the data into training and testing sets (70-30 split)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Range of k values to test
k_values = range(1, 9)  # Testing k from 1 to 8

# Lists to store training and testing accuracy
train_accuracy = []
test_accuracy = []

# Train and evaluate k-NN models with different values of k
print("Training k-NN models with different numbers of neighbors...")
for k in k_values:
    # Create and train k-NN classifier
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train_scaled, y_train)
    
    # Calculate training accuracy
    y_train_pred = knn.predict(X_train_scaled)
    train_acc = accuracy_score(y_train, y_train_pred)
    train_accuracy.append(train_acc)
    
    # Calculate testing accuracy
    y_test_pred = knn.predict(X_test_scaled)
    test_acc = accuracy_score(y_test, y_test_pred)
    test_accuracy.append(test_acc)
    
    print(f"k = {k}: Training Accuracy = {train_acc:.4f}, Testing Accuracy = {test_acc:.4f}")

# Create professional plot
plt.figure(figsize=(10, 6))
plt.plot(k_values, test_accuracy, 'b-', linewidth=2.5, label='Testing Accuracy')
plt.plot(k_values, train_accuracy, color='#FF8C00', linewidth=2.5, label='Training Accuracy')

# Customize plot appearance
plt.xlabel('Number of Neighbors', fontsize=14)
plt.ylabel('Accuracy', fontsize=14)
plt.title('k-NN Varying Number of Neighbors', fontsize=16, fontweight='bold')
plt.xticks(k_values, fontsize=12)
plt.yticks(fontsize=12)
plt.legend(fontsize=12, frameon=True, facecolor='white', edgecolor='gray')
plt.grid(True, linestyle='--', alpha=0.7)
plt.ylim(0.65, 1.01)  # Match the y-axis scale with the reference image

# Add annotations for optimal k
best_k = k_values[np.argmax(test_accuracy)]
max_test_acc = max(test_accuracy)
plt.annotate(f'Optimal k = {best_k}\nAccuracy = {max_test_acc:.4f}',
             xy=(best_k, max_test_acc),
             xytext=(best_k + 0.5, max_test_acc - 0.05),
             arrowprops=dict(facecolor='black', shrink=0.05, width=1.5),
             fontsize=10,
             bbox=dict(boxstyle="round,pad=0.3", fc="white", ec="gray", alpha=0.8))

# Add a professional footer with dataset info
plt.figtext(0.5, 0.01, 
            f"Smart Traffic Congestion Control System | {len(traffic_data)} samples | {sum(y)/len(y):.1%} high congestion instances",
            ha="center", fontsize=10, style='italic')

# Improve layout and save
plt.tight_layout(rect=[0, 0.03, 1, 0.97])
plt.savefig('knn_traffic_congestion_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# Detailed evaluation of best model
print(f"\nDetailed Evaluation for Optimal Model (k={best_k}):")
best_knn = KNeighborsClassifier(n_neighbors=best_k)
best_knn.fit(X_train_scaled, y_train)
y_pred = best_knn.predict(X_test_scaled)

print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=['Low Congestion', 'High Congestion']))

print("\nConfusion Matrix:")
cm = confusion_matrix(y_test, y_pred)
print(cm)

# Feature importance analysis (using correlation for k-NN since it doesn't have built-in feature importance)
print("\nFeature importance analysis (correlation with congestion class):")
correlation = X.corrwith(traffic_data['congestion_class']).sort_values(ascending=False)
for feature, corr in correlation.items():
    print(f"{feature}: {corr:.4f}")

# Summary of findings
print("\nSummary of Traffic Congestion Prediction Analysis:")
print("=" * 60)
print(f"1. The optimal number of neighbors for k-NN is {best_k} with accuracy {max_test_acc:.4f}")
print(f"2. Most important features for congestion prediction: {', '.join(correlation.index[:3])}")
print(f"3. Total data points analyzed: {len(traffic_data)} with {sum(y)/len(y):.1%} high congestion instances")
print(f"4. The model shows {'low' if abs(max(train_accuracy) - max(test_accuracy)) > 0.1 else 'minimal'} overfitting")
print("=" * 60)
print("\nThis analysis demonstrates the effectiveness of machine learning for traffic congestion prediction,")
print("supporting the Smart Traffic Congestion Control System implementation.") 